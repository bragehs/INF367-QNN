{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MANDATORY ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1) data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 7.9\n",
      "0 2\n"
     ]
    }
   ],
   "source": [
    "print(np.min(X), np.max(X))\n",
    "print(np.min(Y), np.max(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Encoding and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at first we normalize the data from 0 to pi, and then implement angle encoding\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from qiskit import QuantumCircuit, transpile, assemble\n",
    "from qiskit_aer import Aer, AerSimulator\n",
    "from qiskit.visualization import plot_histogram\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit_algorithms.optimizers import SPSA\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_encoding(qc, sample):\n",
    "    for qubit in range(len(qc.qubits)):\n",
    "        qc.rx(sample[qubit], qubit)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) choosing Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.3, random_state=42) # 70% training \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) # 15% validation, 15% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 4\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('1111', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = '\\u03B8'\n",
    "\n",
    "def real_amplitudes(data_point,parameters, layers = num_layers):\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    angle_encoding(qc, data_point)\n",
    "\n",
    "    param_index = 0\n",
    "\n",
    "    for layer in range(layers):\n",
    "        for qubit in range(len(qc.qubits)):\n",
    "            qc.ry(parameters[param_index], qubit)\n",
    "            param_index += 1\n",
    "        qc.barrier()\n",
    "        \n",
    "        for qubit in range(len(qc.qubits)-1):\n",
    "            qc.cx(qubit, qubit+1)\n",
    "        qc.barrier()\n",
    "\n",
    "    return qc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_decoding(output):\n",
    "    return int(output, 2) % 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(updated_params):\n",
    "    loss = 0\n",
    "    transpilation_cache = {}\n",
    "    backend = AerSimulator(method = 'statevector')\n",
    "\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        qc = real_amplitudes(x, updated_params, layers=num_layers)\n",
    "        qc.measure_all()\n",
    "        shots = 100\n",
    "\n",
    "        circuit_key = tuple(x)  # Convert input to immutable tuple for dict key\n",
    "        if circuit_key not in transpilation_cache:\n",
    "            transpiled_qc = transpile(qc, backend)  # Done only for new circuits\n",
    "            transpilation_cache[circuit_key] = transpiled_qc\n",
    "\n",
    "        tqc = transpilation_cache[circuit_key]\n",
    "        \n",
    "        job = backend.run(tqc, shots=shots)\n",
    "        result = job.result()\n",
    "        counts = result.get_counts(qc)\n",
    "\n",
    "        count_classes = {0: 0, 1: 0, 2: 0}\n",
    "        for output, count in counts.items():\n",
    "            class_num = data_decoding(output)\n",
    "            count_classes[class_num] += count\n",
    "\n",
    "        expectation_value = 0    \n",
    "        for class_num, count in count_classes.items():\n",
    "            probability = count / shots\n",
    "            expectation_value += class_num * probability\n",
    "        \n",
    "\n",
    "        loss += np.sqrt((y - expectation_value) ** 2)\n",
    "        \n",
    "     \n",
    "    loss = loss / len(X_train)\n",
    "\n",
    "    print(f\"Parameters: {updated_params} loss: {loss}\")\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 2, 1, 2, 1, 0, 2])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: [ 0.40965767  0.12046764  1.14698224  1.02737926  0.620943    0.61949672\n",
      "  0.42512417  0.50856737 -0.11277331  0.91535068  0.47820765  0.44227581] loss: 0.7626666666666666\n",
      "Parameters: [0.00965767 0.52046764 0.74698224 0.62737926 1.020943   1.01949672\n",
      " 0.02512417 0.10856737 0.28722669 0.51535068 0.07820765 0.84227581] loss: 0.6789523809523808\n",
      "Parameters: [ 0.40965767  0.52046764  1.14698224  0.62737926  0.620943    0.61949672\n",
      "  0.42512417  0.50856737 -0.11277331  0.51535068  0.07820765  0.44227581] loss: 0.6482857142857141\n",
      "Parameters: [0.00965767 0.12046764 0.74698224 1.02737926 1.020943   1.01949672\n",
      " 0.02512417 0.10856737 0.28722669 0.91535068 0.47820765 0.84227581] loss: 0.7856190476190477\n",
      "Parameters: [ 0.40965767  0.52046764  0.74698224  0.62737926  0.620943    1.01949672\n",
      "  0.02512417  0.10856737 -0.11277331  0.51535068  0.47820765  0.44227581] loss: 0.6786666666666669\n",
      "Parameters: [0.00965767 0.12046764 1.14698224 1.02737926 1.020943   0.61949672\n",
      " 0.42512417 0.50856737 0.28722669 0.91535068 0.07820765 0.84227581] loss: 0.703142857142857\n",
      "Parameters: [ 0.00965767  0.52046764  1.14698224  1.02737926  0.620943    0.61949672\n",
      "  0.42512417  0.10856737 -0.11277331  0.91535068  0.07820765  0.44227581] loss: 0.8430476190476192\n",
      "Parameters: [0.40965767 0.12046764 0.74698224 0.62737926 1.020943   1.01949672\n",
      " 0.02512417 0.50856737 0.28722669 0.51535068 0.47820765 0.84227581] loss: 0.6930476190476192\n",
      "Parameters: [0.40965767 0.52046764 0.74698224 1.02737926 0.620943   0.61949672\n",
      " 0.02512417 0.50856737 0.28722669 0.91535068 0.47820765 0.44227581] loss: 0.8195238095238097\n",
      "Parameters: [ 0.00965767  0.12046764  1.14698224  0.62737926  1.020943    1.01949672\n",
      "  0.42512417  0.10856737 -0.11277331  0.51535068  0.07820765  0.84227581] loss: 0.654285714285714\n",
      "Parameters: [0.40965767 0.12046764 0.74698224 1.02737926 0.620943   1.01949672\n",
      " 0.42512417 0.10856737 0.28722669 0.51535068 0.47820765 0.44227581] loss: 0.7432380952380949\n",
      "Parameters: [ 0.00965767  0.52046764  1.14698224  0.62737926  1.020943    0.61949672\n",
      "  0.02512417  0.50856737 -0.11277331  0.91535068  0.07820765  0.84227581] loss: 0.742\n",
      "Parameters: [ 0.40965767  0.52046764  0.74698224  1.02737926  0.620943    1.01949672\n",
      "  0.02512417  0.10856737 -0.11277331  0.51535068  0.47820765  0.84227581] loss: 0.8431428571428569\n"
     ]
    }
   ],
   "source": [
    "initial_parameters = np.random.rand(num_layers * num_qubits)\n",
    "\n",
    "# Gradient Descent optimizer\n",
    "optimizer = SPSA(maxiter=50)\n",
    "\n",
    "# Optimize the parameters\n",
    "optimized = optimizer.minimize(fun=objective_function, x0=initial_parameters)\n",
    "\n",
    "print(\"Optimized Parameters:\", optimized.x)\n",
    "print(\"Minimum Cost:\", optimized.fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_point, optimized_params):\n",
    "    qc = real_amplitudes(data_point, optimized_params)\n",
    "    qc.measure_all()\n",
    "\n",
    "    backend = AerSimulator(method = 'statevector')\n",
    "    tqc = transpile(qc, backend)\n",
    "    shots = 100\n",
    "    job = backend.run(tqc, shots=shots)\n",
    "    result = job.result()\n",
    "    counts = result.get_counts(qc)\n",
    "\n",
    "    count_classes = {0: 0, 1: 0, 2: 0}\n",
    "        \n",
    "    # Decode each measurement outcome and aggregate counts for each class\n",
    "    for output, count in counts.items():\n",
    "        class_num = data_decoding(output)\n",
    "        count_classes[class_num] += count\n",
    "    \n",
    "    # Calculate probabilities for each class\n",
    "    probabilities = {class_num: count / shots for class_num, count in count_classes.items()}\n",
    "    \n",
    "    # Determine the predicted class by choosing the class with the highest probability\n",
    "    predicted_class = max(probabilities, key=probabilities.get)\n",
    "    \n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dataset(X, optimized_params):\n",
    "    return [predict(data_point, optimized_params) for data_point in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 1, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict_dataset(X_test, optimized.x)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5217391304347826"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = accuracy_score(y_test, predictions)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 0, 2, 1, 1, 0, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 1, 2, 0, 0,\n",
       "       2])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
